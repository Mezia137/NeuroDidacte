    <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Morpion</title>
    <link rel="stylesheet" type="text/css" href="../static/styles/style.css">
    <link rel="icon" type="image/png" href="../static/icons/favicon.png">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/3.0.3/socket.io.js"></script>
</head>
<body>
    <header>
        <div class="header-content">
            <a href="/reseausimple"><div id="previouspage-link"><img src="../static/icons/previous.svg" alt="Previous" id="previouspage-icon"></div></a>

            <div style="display: flex;">
                <h1>MORPION</h1>
                <img class="info-icon" style="left: -90px;" src="../static/icons/info.svg" data-infobox-id="null"  onclick="document.getElementById('morpion-tile').classList.toggle('active')"/>
            </div>

            <a href="/"><div id="nextpage-link"><img src="../static/icons/next.svg" alt="Next" id="nextpage-icon"></div></a>

        </div>
    </header>

    <div class="main-content">
        <div class="left-content" style="display: flex; flex-direction: column; align-items: center;">
            <div id="tictactoe-configuration">
                <select id="player1-selection">
                      <option value="0">HUMAIN</option>
                      <option value="1">HASARD</option>
                      <option value="2">RESEAU v0</option>
                      <option value="3" disabled>RESEAU v1</option>
                      <option value="4" disabled>RESEAU v2</option>
                </select>
                <img height="30px" src="../static/icons/cross-shadow.svg"/>
                <button id="play-tictactoe-button" onclick="play()">PLAY</button>
                <img height="30px" src="../static/icons/round-shadow.svg"/>
                <select id="player2-selection">
                      <option value="0">HUMAIN</option>
                      <option value="1">HASARD</option>
                      <option value="2">RESEAU v0</option>
                      <option value="3" disabled>RESEAU v1</option>
                      <option value="4" disabled>RESEAU v2</option>
                </select>
            </div>
            <svg id="board">
                <image x="0" y="0" width="100%" height="100%" href="../static/icons/board.svg"></image>

            </svg>
        </div>
        <div class="right-content">
            <img class="arrow-propagation" src="../static/icons/fparrow.svg" width="60%" onclick="document.getElementById('forward-tile').classList.toggle('active')">
            <svg id="schema">
                <line class="ligne" x1="9%" y1="93%" x2="90%" y2="15%"/>
                <line class="ligne" x1="9%" y1="84%" x2="90%" y2="24%"/>
                <line class="ligne" x1="9%" y1="75%" x2="90%" y2="33%"/>
                <line class="ligne" x1="9%" y1="63%" x2="90%" y2="45%"/>
                <line class="ligne" x1="9%" y1="54%" x2="90%" y2="54%"/>
                <line class="ligne" x1="9%" y1="45%" x2="90%" y2="63%"/>
                <line class="ligne" x1="9%" y1="33%" x2="90%" y2="75%"/>
                <line class="ligne" x1="9%" y1="24%" x2="90%" y2="84%"/>
                <line class="ligne" x1="9%" y1="15%" x2="90%" y2="93%"/>

                <rect class="info-box" x="5%" y="5%" width="8%" height="90%"></rect>
                <rect class="info-box" x="85%" y="5%" width="10%" height="90%"></rect>

                <circle class="info-box" cx="50%" cy="54.5%" r="31.5%" fill="#ff0000"/>
                <text x="45.5%" y="54%" class="schema-text">
                    <tspan>ALPHA</tspan>
                    <tspan x="46.5%" dy="25px">ZERO</tspan>
                </text>

                <image class="info-icon" x="6%" y="6.5%" href="../static/icons/info.svg" data-infobox-id="infobox1"/>
                <image class="info-icon" x="48.5%" y="70%" href="../static/icons/info.svg" data-infobox-id="infobox2"/>
                <image class="info-icon" x="86%" y="6.5%" href="../static/icons/info.svg" data-infobox-id="infobox3"/>



            </svg>
            <img class="arrow-propagation" src="../static/icons/bparrow.svg" width="60%" onclick="document.getElementById('backward-tile').classList.toggle('active')">
        </div>
    </div>
    <div id="infobox1" class="infobox"><p>La couche d'entrée prend les 9 valeures du plateau: 1 si il y a une croix, -1 si il y a un rond et 0 si il n'y a rien.</p></div>
    <div id="infobox2" class="infobox"><p>AlphaZero est trop complexe pour être schématisé simplement.</p></div>
    <div id="infobox3" class="infobox"><p>La couche de sortie renvoie une probabilité par case. Le reseau joue là où elle est la plus élevée.</p></div>
    <div class='tile' id="morpion-tile">
        <button class="exit-tile-button" onclick="document.getElementById('morpion-tile').classList.toggle('active')">fermer</button>
        <div class="tile-content">
            <h1>ALPHA ZERO</h1>
            <div style="margin: 50px 0;">
                <br>
                <br>
                <p>CETTE PAGE EST ENCORE EN DEVELOPPEMENT</p>
                <br>
                <br>
                <p>Maintenant que vous avez une idée de ce que peut faire un reseau de neurones simple, voici le niveau au dessus : AlphaZero.</p>
                <p><a href="https://fr.wikipedia.org/wiki/AlphaZero" target="_blank">AlphaZero</a> est un modele d'intelligence artificielle par réseaux de neurones. Grâce à l'utilisation de réseaux de neurones profonds et de l'apprentissage par renforcement, AlphaZero a prouvé sa capacité à maîtriser des jeux complexes comme les échecs, le jeu de go et le shogi, dépassant les performances des champions humains et des programmes les plus avancés.</p>
                <p>La base d'AlphaZero réside dans une architecture de réseau neuronal profond, prenant l'état actuel du jeu en entrée et générant des prédictions intelligentes sur les mouvements futurs. Grâce à une méthode d'entraînement itérative basée sur la rétropropagation, AlphaZero affine continuellement ses stratégies en jouant contre lui-même, tirant des leçons de ses succès et de ses échecs pour s'améliorer en permanence.</p>
                <p>Ce qui différencie AlphaZero des approches précédentes, c'est son autonomie dans l'apprentissage. Contrairement aux programmes traditionnels qui nécessitaient des bases de données d'ouvertures et de finales créées par des humains, AlphaZero part de zéro, développant ses propres tactiques et stratégies à partir de ses interactions avec le jeu. Cette capacité à apprendre de manière autonome ouvre des perspectives excitantes pour l'IA, offrant un moyen novateur de résoudre des problèmes complexes sans avoir besoin d'une expertise humaine préalable.</p>
                <br>
                <p>Vous pouvez configuerer des parties de morpion sur le plateau. C'est normal si le réseau prend très longtemps à jouer, nous sommes encore sur le développement de cette page.</p>
            </div>

        </div>
    </div>
    <div class='tile' id="forward-tile">
        <button class="exit-tile-button" onclick="document.getElementById('forward-tile').classList.toggle('active')">fermer</button>
        <div class="tile-content">
            <h1>FORWARD PROPAGATION</h1>
            <div style="margin: 50px 0;">
                <p>1. <strong>Entrée du réseau neuronal :</strong><br>
                   L'état actuel du jeu est fourni en entrée au réseau. Dans AlphaZero, cet état est généralement représenté par le plateau de jeu actuel.</p>
                <p>2. <strong>Propagation à travers les couches de convolution :</strong><br>
                   L'état du jeu subit une transformation à travers plusieurs couches de convolution initialement. Ces couches de convolution sont conçues pour extraire des caractéristiques cruciales de l'état du jeu, en capturant les relations spatiales et les motifs.</p>
                <p>3. <strong>Propagation à travers les blocs résiduels :</strong><br>
                   Après les couches de convolution, l'information circule à travers plusieurs blocs résiduels. Ces blocs permettent au réseau d'apprendre des représentations plus complexes et abstraites de l'état du jeu. Les connexions résiduelles au sein de ces blocs facilitent le processus d'entraînement en atténuant le problème du gradient qui disparaît.</p>
                <p>4. <strong>Têtes de politique et de valeur :</strong><br>
                   À la sortie des blocs résiduels, l'information est divisée en deux branches : une pour la tête de politique et une pour la tête de valeur.</p>
                <p>- <strong>Tête de politique :</strong> Ce composant calcule les probabilités d'action pour chaque coup possible à partir de l'état actuel du jeu. Il permet à l'algorithme de sélectionner l'action la plus prometteuse à poursuivre, guidant ainsi le processus de recherche pendant le jeu.</p>
                <p>- <strong>Tête de valeur :</strong> Responsable d'estimer la probabilité de victoire à partir de l'état actuel du jeu. En évaluant la force positionnelle du jeu, la tête de valeur aide l'algorithme à évaluer la situation actuelle du jeu et à prendre des décisions éclairées.</p>
                <p>5. <strong>Sortie :</strong><br>
                   La sortie finale du réseau neuronal comprend la distribution de la politique et l'estimation de la valeur, fournissant des informations précieuses sur la sélection optimale des mouvements et l'évaluation de l'état actuel du jeu.</p>
                <p>En traversant les couches de convolution, les blocs résiduels et les têtes spécialisées, le processus de propagation avant dans le réseau neuronal AlphaZero équipe l'algorithme des outils nécessaires pour comprendre la dynamique du jeu et prendre des décisions stratégiques.</p>
            </div>

        </div>
    </div>
    <div class='tile' id="backward-tile">
        <button class="exit-tile-button" onclick="document.getElementById('backward-tile').classList.toggle('active')">fermer</button>
        <div class="tile-content">
            <h1>BACKWARD PROPAGATION</h1>
            <div style="margin: 50px 0;">
                <p>1. <strong>Calcul du gradient de l'erreur :</strong><br>
                   Au cours de la propagation arrière, l'algorithme commence par calculer le gradient de l'erreur par rapport aux paramètres du réseau. Cela se fait en utilisant la règle de la chaîne pour propager l'erreur depuis les têtes de politique et de valeur jusqu'aux couches précédentes du réseau.</p>
                <p>2. <strong>Propager l'erreur aux blocs résiduels :</strong><br>
                   Une fois que les gradients d'erreur sont calculés au niveau des têtes de politique et de valeur, ils sont propagés en arrière à travers les blocs résiduels. Cette étape permet au réseau d'identifier les zones où les ajustements sont nécessaires pour améliorer les performances.</p>
                <p>3. <strong>Mise à jour des paramètres :</strong><br>
                   Les gradients d'erreur sont ensuite utilisés pour ajuster les paramètres du réseau, y compris les poids des connexions neuronales. Cette mise à jour des paramètres est effectuée en utilisant des algorithmes d'optimisation tels que la descente de gradient stochastique.</p>
                <p>4. <strong>Rétropropagation à travers les couches de convolution :</strong><br>
                   Les gradients d'erreur sont rétropropagés à travers les couches de convolution, permettant au réseau d'ajuster les filtres de convolution pour capturer des caractéristiques plus pertinentes du jeu. Cette étape contribue à améliorer la représentation de l'état du jeu.</p>
                <p>5. <strong>Fin de la propagation arrière :</strong><br>
                   Une fois que les gradients d'erreur ont été propagés à travers toutes les couches du réseau, le processus de rétropropagation se termine. À ce stade, les paramètres du réseau ont été mis à jour pour mieux représenter les données d'entrée et améliorer les performances globales du modèle.</p>
                <p>En combinant la propagation arrière avec la propagation avant, le réseau neuronal AlphaZero est capable d'apprendre efficacement à partir des données d'entraînement, en ajustant ses paramètres pour minimiser l'erreur de prédiction et améliorer ses performances de jeu.</p>
            </div>

        </div>
    </div>


    <script src="{{ url_for('static', filename='js/tictactoe.js') }}"></script>
</body>
</html>